package ma.saifdine.hd.bdccaiapp.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import ma.saifdine.hd.bdccaiapp.dto.ChatRequest;
import ma.saifdine.hd.bdccaiapp.dto.ChatResponse;
import ma.saifdine.hd.bdccaiapp.entity.Message;
import ma.saifdine.hd.bdccaiapp.repository.MessageRepository;
import org.springframework.ai.chat.messages.UserMessage;
import org.springframework.ai.chat.model.ChatModel;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.ollama.api.OllamaOptions;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;

import java.time.LocalDateTime;
import java.util.List;

/**
 * Service principal pour g√©rer les interactions avec Ollama
 * G√®re le chat, l'historique et les conversations
 */
@Service
@RequiredArgsConstructor // G√©n√®re un constructeur avec les champs final
@Slf4j // Active les logs avec lombok
public class OllamaService {

    private final ChatModel chatModel;
    private final MessageRepository messageRepository;

    /**
     * Envoie un message simple √† Ollama et retourne la r√©ponse
     * @param userMessage Le message de l'utilisateur
     * @return La r√©ponse de l'IA
     */
    public String chat(String userMessage) {
        log.info("üì® Message re√ßu: {}", userMessage);

        // Cr√©er un prompt avec le message
        Prompt prompt = new Prompt(new UserMessage(userMessage));

        // Appeler le mod√®le et obtenir la r√©ponse
        org.springframework.ai.chat.model.ChatResponse response = chatModel.call(prompt);

        String aiResponse = response.getResult().getOutput().getContent();
        log.info("ü§ñ R√©ponse g√©n√©r√©e: {}", aiResponse);

        return aiResponse;
    }

    /**
     * Envoie un message avec options avanc√©es et sauvegarde l'historique
     * @param request La requ√™te contenant le message et les options
     * @return ChatResponse avec toutes les informations
     */
    public ChatResponse chatWithHistory(ChatRequest request) {
        long startTime = System.currentTimeMillis();

        log.info("üì® Traitement du message: {}", request.getMessage());

        // Construire les options si sp√©cifi√©es
        OllamaOptions.Builder optionsBuilder = OllamaOptions.builder();

        if (request.getModel() != null) {
            optionsBuilder.model(request.getModel());
        }
        if (request.getTemperature() != null) {
            optionsBuilder.temperature(request.getTemperature());
        }

        OllamaOptions options = optionsBuilder.build();

        // Cr√©er le prompt avec les options
        Prompt prompt = new Prompt(new UserMessage(request.getMessage()), options);

        // Appeler le mod√®le
        org.springframework.ai.chat.model.ChatResponse aiResponse = chatModel.call(prompt);
        String responseText = aiResponse.getResult().getOutput().getContent();

        // Calculer le temps de r√©ponse
        long responseTime = System.currentTimeMillis() - startTime;

        // Sauvegarder dans la base de donn√©es
        Message message = new Message();
        message.setUserMessage(request.getMessage());
        message.setAiResponse(responseText);
        message.setModel(request.getModel() != null ? request.getModel() : "llama2");
        message.setResponseTime(responseTime);
        message.setTimestamp(LocalDateTime.now());

        Message savedMessage = messageRepository.save(message);

        log.info("‚úÖ Message sauvegard√© avec ID: {}", savedMessage.getId());
        log.info("‚è±Ô∏è Temps de r√©ponse: {}ms", responseTime);

        // Construire la r√©ponse
        return ChatResponse.builder()
                .response(responseText)
                .model(message.getModel())
                .timestamp(message.getTimestamp())
                .responseTime(responseTime)
                .messageId(savedMessage.getId())
                .build();
    }

    /**
     * R√©cup√®re l'historique complet des conversations
     * @return Liste de tous les messages
     */
    public List<Message> getHistory() {
        log.info("üìö R√©cup√©ration de l'historique");
        return messageRepository.findAll();
    }

    /**
     * R√©cup√®re les N derniers messages
     * @return Liste des 10 derniers messages
     */
    public List<Message> getRecentHistory() {
        log.info("üìö R√©cup√©ration des messages r√©cents");
        return messageRepository.findTop10ByOrderByTimestampDesc();
    }

    /**
     * Streaming de r√©ponse (pour les r√©ponses en temps r√©el)
     * @param userMessage Le message de l'utilisateur
     * @return Flux de tokens de r√©ponse
     */
    public Flux<String> chatStream(String userMessage) {
        log.info("üåä D√©marrage du streaming pour: {}", userMessage);

        Prompt prompt = new Prompt(new UserMessage(userMessage));

        // Stream la r√©ponse token par token
        return chatModel.stream(prompt)
                .map(response -> response.getResult().getOutput().getContent());
    }

    /**
     * Supprime l'historique complet
     */
    public void clearHistory() {
        log.warn("üóëÔ∏è Suppression de l'historique");
        messageRepository.deleteAll();
    }
}